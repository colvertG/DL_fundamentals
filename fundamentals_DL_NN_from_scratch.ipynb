{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal (2 capas), desde cero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Solamente para usuarios de Jupyter Themes\n",
    "#from jupyterthemes import jtplot\n",
    "#jtplot.style(grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar MNIST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mnist.png\">\n",
    "<caption><left> Fig 1. Muestra MNIST </left></caption>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_images import get_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST path\n",
    "mnist_path = r'C:\\Users\\colve\\Documents\\DATOS TESIS\\mnist_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_num, y_train_num, x_test_num, y_test_num = get_images(mnist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_num.shape)\n",
    "print(y_train_num.shape)\n",
    "print(x_test_num.shape)\n",
    "print(y_test_num.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir imágenes en vectores, y a float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_num[:50000].reshape(50000, -1).astype(np.float32)/255\n",
    "y_train = y_train_num[:50000].reshape(50000, 1)\n",
    "\n",
    "x_val = x_train_num[50000:].reshape(10000, -1).astype(np.float32)/255\n",
    "y_val = y_train_num[50000:].reshape(10000, 1)\n",
    "\n",
    "x_test = x_test_num.copy().reshape(10000, -1).astype(np.float32)/255\n",
    "y_test = y_test_num.copy().reshape(10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000, 1)\n",
      "(10000, 784)\n",
      "(10000, 1)\n",
      "(10000, 784)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape) #shape (50000, 784)\n",
    "print(y_train.shape) #shape (50000, 1)\n",
    "\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar algunas imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(image):\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen muestreada representa un: [2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnd_idx = np.random.randint(len(y_test))\n",
    "print(f'La imagen muestreada representa un: {y_test[rnd_idx]}')\n",
    "plot_number(x_test_num[rnd_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecuaciones para nuestro modelo\n",
    "\n",
    "\n",
    "$$z^1 = W^1 X + b^1$$\n",
    "\n",
    "$$a^1 = ReLU(z^1) $$\n",
    "\n",
    "$$z^2 = W^2 a^1 + b^2$$\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Neuronal\n",
    "### Dos capas 200-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear 'Mini-batches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    '''\n",
    "    x  #muestras, 784\n",
    "    y #muestras, 1\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle: \n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "        \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(input_size, neurons):\n",
    "    \n",
    "    '''\n",
    "    input_size -> elementos de entrada, 784\n",
    "    neurons -> list [200, 10] con cantidad de neuronas en cada capa\n",
    "    '''\n",
    "    \n",
    "    W1 = np.random.randn(neurons[0], input_size) * 0.001\n",
    "    b1 = np.zeros((neurons[0], 1))\n",
    "    \n",
    "    W2 = np.random.randn(neurons[1], neurons[0]) * 0.001\n",
    "    b2 = np.zeros((neurons[1], 1))\n",
    "    \n",
    "    return {'W1': W1, 'b1':b1, 'W2':W2, 'b2':b2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 784)\n",
      "(10, 200)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "parameters = init_parameters(28*28, [200, 10])\n",
    "print(parameters['W1'].shape)\n",
    "print(parameters['W2'].shape)\n",
    "print(parameters['b2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(x, parameters, activation_fcn):\n",
    "    '''\n",
    "    x tiene la forma (#pixeles, num samples)\n",
    "    '''\n",
    "    z1 = parameters['W1'] @ x + parameters['b1']\n",
    "    a1 = activation_fcn(z1) # devuel fcn. de activa.\n",
    "    z2 = parameters['W2'] @ a1 + parameters['b2']\n",
    "    \n",
    "    return z2, z1, a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores,z1, a1 = scores(x_train[:64].T, parameters, relu) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:64].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_scores = np.exp(x)\n",
    "    sum_exp_scores = np.sum(exp_scores, axis=0)\n",
    "    probs = exp_scores/sum_exp_scores\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_entropy(scores, y, batch_size=64):\n",
    "    probs = softmax(scores)\n",
    "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
    "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
    "    \n",
    "    return probs, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(probs, x, y, z1, a1, scores, parameters, batch_size=64):\n",
    "    grads = {}\n",
    "    probs[y.squeeze(), np.arange(batch_size)] -= 1 # y-hat - y\n",
    "    dz2 = probs.copy()\n",
    "    \n",
    "    dW2 = dz2 @ a1.T / batch_size\n",
    "    db2 = np.sum(dz2, axis =1, keepdims=True) / batch_size\n",
    "    da1 = parameters['W2'].T @ dz2\n",
    "    \n",
    "    dz1 = da1.copy()\n",
    "    dz1[z1 <= 0 ] =0\n",
    "    \n",
    "    dW1 = dz1 @ x \n",
    "    db1 = np.sum(dz1, axis=1, keepdims=True) \n",
    "    \n",
    "    assert parameters['W1'].shape == dW1.shape, 'W1 no igual forma'\n",
    "    assert parameters['W2'].shape == dW2.shape, 'W2 no igual forma'\n",
    "    assert parameters['b1'].shape == db1.shape, 'b1 no igual forma'\n",
    "    assert parameters['b2'].shape == db2.shape, 'b2 no igual forma'\n",
    "    \n",
    "    grads = {'w1':dW1,  'b1':db1, 'W2':dW2, 'b2':db2}\n",
    "    \n",
    "    return grads\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat, cost = x_entropy(scores, y_train[:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3025800329624975\n"
     ]
    }
   ],
   "source": [
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = backward(y_hat, x_train[:64], y_train[:64],z1, a1, scores, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x_data, y_data, mb_size=64):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (x, y) in enumerate(create_minibatches(mb_size, x_data, y_data)):\n",
    "        scores2, z1, a1 = scores(x.T, parameters, relu)\n",
    "        y_hat, cost = x_entropy(scores2, y, batch_size=len(x))\n",
    "        \n",
    "        correct += np.sum(np.argmax(y_hat, axis=0) == y.squeeze())\n",
    "        total += y_hat.shape[1]\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(epochs, parameters, mb_size=64, learning_rate = 1e-3):\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
    "            scores2, z1, a1 = scores(x.T, parameters=parameters, activation_fcn=relu)\n",
    "            y_hat, cost = x_entropy(scores2, y, batch_size=len(x))\n",
    "            grads = backward(y_hat, x, y, z1, a1, scores2, parameters, batch_size=len(x))\n",
    "            \n",
    "            parameters['W1'] = parameters['W1'] - learning_rate*grads['w1']\n",
    "            parameters['b1'] = parameters['b1'] - learning_rate*grads['b1']\n",
    "            parameters['b2'] = parameters['b2'] - learning_rate*grads['b2']\n",
    "            parameters['W2'] = parameters['W2'] - learning_rate*grads['W2']\n",
    "            \n",
    "        print(f'costo es: {cost}, y accuracy: {accuracy(x_val, y_val, mb_size)}')\n",
    "    return parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m learning_rate \u001b[39m=\u001b[39m \u001b[39m1e-2\u001b[39m\n\u001b[0;32m      3\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[1;32m----> 4\u001b[0m parameters \u001b[39m=\u001b[39m train(epochs\u001b[39m=\u001b[39;49mepochs, parameters\u001b[39m=\u001b[39;49mparameters, mb_size\u001b[39m=\u001b[39;49mmb_size, learning_rate\u001b[39m=\u001b[39;49mlearning_rate)\n",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs, parameters, mb_size, learning_rate)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      3\u001b[0m     \u001b[39mfor\u001b[39;00m i, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(create_minibatches(mb_size, x_train, y_train)):\n\u001b[1;32m----> 4\u001b[0m         scores2, z1, a1 \u001b[39m=\u001b[39m scores(x\u001b[39m.\u001b[39;49mT, parameters\u001b[39m=\u001b[39;49mparameters, activation_fcn\u001b[39m=\u001b[39;49mrelu)\n\u001b[0;32m      5\u001b[0m         y_hat, cost \u001b[39m=\u001b[39m x_entropy(scores2, y, batch_size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(x))\n\u001b[0;32m      6\u001b[0m         grads \u001b[39m=\u001b[39m backward(y_hat, x, y, z1, a1, scores2, parameters, batch_size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(x))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "mb_size = 512\n",
    "learning_rate = 1e-2\n",
    "epochs = 20\n",
    "parameters = train(epochs=epochs, parameters=parameters, mb_size=mb_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m accuracy(x_train, y_train, mb_size)\n",
      "Cell \u001b[1;32mIn[31], line 5\u001b[0m, in \u001b[0;36maccuracy\u001b[1;34m(x_data, y_data, mb_size)\u001b[0m\n\u001b[0;32m      3\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(create_minibatches(mb_size, x_data, y_data)):\n\u001b[1;32m----> 5\u001b[0m     scores2, z1, a1 \u001b[39m=\u001b[39m scores(x\u001b[39m.\u001b[39;49mT, parameters, relu)\n\u001b[0;32m      6\u001b[0m     y_hat, cost \u001b[39m=\u001b[39m x_entropy(scores2, y, batch_size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(x))\n\u001b[0;32m      8\u001b[0m     correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39margmax(y_hat, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m y\u001b[39m.\u001b[39msqueeze())\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "accuracy(x_train, y_train, mb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(x_test, y_test, mb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    scores2, _, _ = scores(x, parameters, relu)\n",
    "    return np.argmax(scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[0].reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(y_test))\n",
    "plot_number(x_test_num[idx])\n",
    "pred = predict(x_test[idx].reshape(-1, 1))\n",
    "print(f'el valor predicho es: {pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
